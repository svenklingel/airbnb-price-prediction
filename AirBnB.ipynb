{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svenklingel/airbnb-price-prediction/blob/main/AirBnB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hoh2FEBoWvl"
      },
      "outputs": [],
      "source": [
        "!pip install osmnx mapclassify folium matplotlib catboost optuna dcor\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import optuna\n",
        "import osmnx as ox\n",
        "import dcor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.metrics import root_mean_squared_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from shapely.geometry import Point\n",
        "from scipy.stats import spearmanr\n",
        "from shapely.geometry import box\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfQzwuj0s6Mn"
      },
      "source": [
        "Data exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZCqCWdioWvo"
      },
      "outputs": [],
      "source": [
        "airbnb_df = pd.read_csv(r\"/content/AB_NYC_2019.csv\")\n",
        "airbnb_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B38Ye9NoWvq"
      },
      "outputs": [],
      "source": [
        "# GeoDataFrame created from Dataframe and latitude/longitude columns\n",
        "airbnb_gdf = gpd.GeoDataFrame(airbnb_df, geometry=gpd.points_from_xy(airbnb_df.longitude, airbnb_df.latitude))\n",
        "airbnb_gdf.set_crs('epsg:4326', inplace=True)\n",
        "airbnb_gdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzmiOLonoWvr"
      },
      "outputs": [],
      "source": [
        "# 1. Load boroughs polygons\n",
        "boroughs_gdf = gpd.read_file(\"boroughs.json\")\n",
        "\n",
        "# 2. Ensure the same CRS for both GeoDataFrames\n",
        "airbnb_gdf = airbnb_gdf.to_crs(epsg=2263)\n",
        "boroughs_gdf = boroughs_gdf.to_crs(epsg=2263)\n",
        "\n",
        "# 3. Spatial join: assign points to borough polygons\n",
        "joined_gdf = gpd.sjoin(airbnb_gdf, boroughs_gdf, how=\"inner\", predicate=\"within\")\n",
        "\n",
        "# 4. Count listings per borough\n",
        "listing_counts = joined_gdf['boro_name'].value_counts().rename_axis('boro_name').reset_index(name='listing_count')\n",
        "\n",
        "# 5. Calculate area (in km²)\n",
        "boroughs_gdf['area_km2'] = boroughs_gdf.geometry.area / 1e6\n",
        "\n",
        "# 6. Merge boroughs with listing counts\n",
        "boroughs_gdf = boroughs_gdf.merge(listing_counts, on='boro_name', how='left')\n",
        "boroughs_gdf['listing_count'] = boroughs_gdf['listing_count'].fillna(0)\n",
        "\n",
        "# 7. Calculate density (Listings/km²)\n",
        "boroughs_gdf['density'] = boroughs_gdf['listing_count'] / boroughs_gdf['area_km2']\n",
        "\n",
        "# 8. Calculate proportional share (in %)\n",
        "total_listings = boroughs_gdf['listing_count'].sum()\n",
        "boroughs_gdf['proportion'] = (boroughs_gdf['listing_count'] / total_listings) * 100\n",
        "\n",
        "# 9. Label with all information\n",
        "boroughs_gdf['label'] = boroughs_gdf.apply(\n",
        "    lambda row: f\"{row['boro_name']} ({int(row['listing_count'])} Listings, \"\n",
        "                f\"{row['density']:.1f}/km², {row['proportion']:.1f}%)\", axis=1\n",
        ")\n",
        "\n",
        "boroughs_map = boroughs_gdf.explore(\n",
        "    column=\"label\",\n",
        "    cmap=\"Set1\",\n",
        "    tooltip=[\"boro_name\", \"proportion\"],\n",
        "    legend=True,\n",
        "    legend_kwds={\n",
        "        \"caption\": \"Boroughs and proportion of listings\",\n",
        "        \"colorbar\": False\n",
        "    }\n",
        ")\n",
        "\n",
        "listings_map = airbnb_gdf.explore(m=boroughs_map)\n",
        "listings_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR0qWi9ToWvs"
      },
      "source": [
        "Exploration of column meanings, datatypes, missing values, distributions, skewness etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jILtjvuLoWvu"
      },
      "outputs": [],
      "source": [
        "# Duplicated rows\n",
        "airbnb_gdf.duplicated().sum() # 0 Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi9RbBCwoWvv"
      },
      "outputs": [],
      "source": [
        "# Missing values\n",
        "airbnb_gdf.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ORf26nZoWvw"
      },
      "outputs": [],
      "source": [
        "# Unique values per column\n",
        "airbnb_gdf.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOd2nnIeoWvx"
      },
      "outputs": [],
      "source": [
        "# Unique neighbourhood groups\n",
        "airbnb_gdf['neighbourhood_group'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD2bTNPzoWvy"
      },
      "outputs": [],
      "source": [
        "# Proportion of listenings per borough\n",
        "borough_counts = airbnb_gdf['neighbourhood_group'].value_counts()\n",
        "borough_counts.plot.pie(autopct='%1.1f%%')\n",
        "plt.title('Listenings per Borough',loc=\"center\")\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIy4AxvsoWvz"
      },
      "outputs": [],
      "source": [
        "# group by neighbourhood_group and calculate median price\n",
        "borough_price = airbnb_gdf.groupby('neighbourhood_group')['price'].median()\n",
        "\n",
        "borough_price = borough_price.to_dict()\n",
        "\n",
        "labels = list(borough_price.keys())\n",
        "values = list(borough_price.values())\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(labels, values, color='cornflowerblue')\n",
        "plt.ylabel(\"Median price ($)\")\n",
        "plt.title(\"Median price per borough\")\n",
        "plt.xticks(rotation=20)\n",
        "\n",
        "# Werte über die Balken schreiben\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height , f\"{height:.2f} $\", ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JJXxYwpoWv0"
      },
      "outputs": [],
      "source": [
        "# Unique room types\n",
        "airbnb_gdf['room_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS6mVSKdoWv1"
      },
      "outputs": [],
      "source": [
        "# Proportion, counts of room types\n",
        "room_type_counts = airbnb_gdf['room_type'].value_counts()\n",
        "room_type_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "room_type_counts.plot.pie(autopct='%1.1f%%')\n",
        "plt.title('Listings per room type',loc=\"center\")\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WXrOHXXobYfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N7xvfgmoWv2"
      },
      "outputs": [],
      "source": [
        "# group by neighbourhood_group and calculate average price\n",
        "room_type_price = airbnb_gdf.groupby('room_type')['price'].median()\n",
        "room_type_price = room_type_price.to_dict()\n",
        "\n",
        "labels = list(room_type_price.keys())\n",
        "values = list(room_type_price.values())\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(labels, values, color='cornflowerblue')\n",
        "plt.ylabel(\"Median price ($)\")\n",
        "plt.title(\"Median price per room type\")\n",
        "plt.xticks(rotation=20)\n",
        "\n",
        "# Werte über die Balken schreiben\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height , f\"{height:.2f} $\", ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spatial distribution per room type\n",
        "roomtype_map = airbnb_gdf.explore(\n",
        "    column=\"room_type\",\n",
        "    cmap=\"tab10\",\n",
        "    legend=True,\n",
        "    legend_kwds={\n",
        "        \"caption\": \"Distribution of room type\",\n",
        "        \"colorbar\": False\n",
        "    }\n",
        ")\n",
        "roomtype_map"
      ],
      "metadata": {
        "id": "kTBE5vzFmKOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5APWRCSNoWv3"
      },
      "outputs": [],
      "source": [
        "# Proportion of listenings per neighbourhood\n",
        "neighbourhood_percentage = airbnb_gdf['neighbourhood'].value_counts(normalize=True).mul(100).round(1).astype(str)\n",
        "neighbourhood_percentage.sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2bvA546oWv3"
      },
      "outputs": [],
      "source": [
        "# Number of unique neighbourhoods\n",
        "len(airbnb_gdf['neighbourhood'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbSgslPioWv3"
      },
      "outputs": [],
      "source": [
        "# Histogram before cleaning\n",
        "# Numeric columns\n",
        "numeric_cols = airbnb_gdf.select_dtypes(include='number').columns.tolist()\n",
        "numeric_cols.append(\"calculated_host_listings_count\")\n",
        "# Not relevant columns\n",
        "for col in [\"id\", \"host_id\", \"longitude\", \"latitude\"]:\n",
        "    if col in numeric_cols:\n",
        "        numeric_cols.remove(col)\n",
        "\n",
        "# Histograms\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(airbnb_df[col].dropna(), bins=200, edgecolor='k', color='skyblue')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots against 'price' before cleaning\n",
        "for col in numeric_cols:\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(airbnb_df[col], airbnb_df['price'], alpha=0.5, edgecolor='k')\n",
        "    plt.title(f'Price vs {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Price')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Whs1bSUyUh29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check correlations before data cleaning\n",
        "cols_for_correlation = ['price', 'minimum_nights', 'number_of_reviews',\n",
        "                        'reviews_per_month', 'calculated_host_listings_count',\n",
        "                        'availability_365', 'longitude', 'latitude']\n",
        "\n",
        "# Pearson correlation (linear)\n",
        "pearson_corr_orig = airbnb_gdf[cols_for_correlation].corr(method='pearson')\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(pearson_corr_orig, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Pearson Correlation\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Spearman correlation (monotonic, non-linear)\n",
        "spearman_corr = airbnb_gdf[cols_for_correlation].corr(method='spearman')\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Spearman Correlation\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jrdd1s_LU577"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roWe_hXNvfmh"
      },
      "source": [
        "Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5XD3Q0moWv4"
      },
      "outputs": [],
      "source": [
        "# Metrics of the target ariable\n",
        "airbnb_df['price'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BoiIueKoWv6"
      },
      "outputs": [],
      "source": [
        "# Boxplot of price\n",
        "airbnb_gdf.boxplot(column='price')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Oc13NGNoWv7"
      },
      "outputs": [],
      "source": [
        "# Price outliers: Remove the first and last 1% outliers (below 1th percentile, above 95th percentile)\n",
        "lower_bound = airbnb_gdf['price'].quantile(0.01)\n",
        "upper_bound = airbnb_gdf['price'].quantile(0.95)\n",
        "\n",
        "print(f\"Lower Bound (1th percentile): {lower_bound}\")\n",
        "print(f\"Upper Bound (95th percentile): {upper_bound}\")\n",
        "\n",
        "# Count of outliers below the lower bound\n",
        "outliers_below = airbnb_gdf[airbnb_gdf['price'] < lower_bound].shape[0]\n",
        "print(f\"Number of outliers below the lower bound: {outliers_below}\")\n",
        "\n",
        "# Count of outliers above the upper bound\n",
        "outliers_above = airbnb_gdf[airbnb_gdf['price'] > upper_bound].shape[0]\n",
        "print(f\"Number of outliers above the upper bound: {outliers_above}\")\n",
        "\n",
        "# Filter the data to remove outliers\n",
        "filtered_gdf = airbnb_gdf[(airbnb_gdf['price'] >= lower_bound) & (airbnb_gdf['price'] <= upper_bound)]\n",
        "\n",
        "# Shapes of old and filtered data\n",
        "print(f\"Original DataFrame shape: {airbnb_gdf.shape}\")\n",
        "print(f\"Filtered DataFrame shape: {filtered_gdf.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLP-BrZsoWv7"
      },
      "outputs": [],
      "source": [
        "# Histogram of price of filtered_df\n",
        "plt.hist(filtered_gdf['price'], bins=250, edgecolor='k')\n",
        "plt.title('Price without outliers')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3ISva81oWv8"
      },
      "outputs": [],
      "source": [
        "# Logarithmic transformation of price to reuce right skew\n",
        "filtered_gdf['price_log'] = np.log(filtered_gdf['price'])\n",
        "plt.hist(filtered_gdf['price_log'], bins=200, edgecolor='k')\n",
        "plt.title('Filtered and log. transformed price')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uldU4NiRoWv8"
      },
      "outputs": [],
      "source": [
        "# Numeric columns after cleaning based on price variable\n",
        "numeric_cols = filtered_gdf.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "for col in [\"id\", \"host_id\", \"longitude\", \"latitude\"]:\n",
        "    if col in numeric_cols:\n",
        "        numeric_cols.remove(col)\n",
        "\n",
        "numeric_cols\n",
        "\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(filtered_gdf[col].dropna(), bins=200, edgecolor='k', color='skyblue')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots against 'price' after cleaning\n",
        "for col in numeric_cols:\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(airbnb_df[col], airbnb_df['price'], alpha=0.5, edgecolor='k')\n",
        "    plt.title(f'Price vs {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Price')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "QKLCAyHdu0bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots against 'price' after applying log transformation\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "\n",
        "    # Apply log transformation to both axes\n",
        "    plt.scatter(np.log1p(airbnb_df[col]), np.log1p(airbnb_df['price']), alpha=0.5, edgecolor='k')\n",
        "\n",
        "    # Set the title and labels\n",
        "    plt.title(f'Log(Price) vs Log({col})')\n",
        "    plt.xlabel(f'Log({col})')\n",
        "    plt.ylabel('Log(Price)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "grh3hY0cIdqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huWNHQzZvu2e"
      },
      "source": [
        "Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSkd408NoWv-"
      },
      "outputs": [],
      "source": [
        "cols_for_correlation = ['price', 'minimum_nights', 'number_of_reviews',\n",
        "                        'reviews_per_month', 'calculated_host_listings_count',\n",
        "                        'availability_365', 'longitude', 'latitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KNez9F4oWv-"
      },
      "outputs": [],
      "source": [
        "# Correaltions after cleaning\n",
        "# Pearson correlation better for linear relationships\n",
        "pearson_corr = filtered_gdf[cols_for_correlation].corr(method='pearson')\n",
        "\n",
        "# Correlation hetammap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Pearson correlation\")\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Spearman correlation better for non-linear relationships\n",
        "spearman_corr = filtered_gdf[cols_for_correlation].corr(method='spearman')\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "ax = sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "plt.title(\"Spearman correlation\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXLJ23ProWwI"
      },
      "outputs": [],
      "source": [
        "# Relevance of several distance based features\n",
        "# Merged multipolygon of all boroughs\n",
        "multi_poly = boroughs_gdf.dissolve()\n",
        "multi_poly.explore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCcnirEVoWwJ"
      },
      "outputs": [],
      "source": [
        "# MutiPolygon of all boroughs used to fetch OSM data\n",
        "multi_poly_4326 = multi_poly.to_crs(epsg=4326)\n",
        "poly=multi_poly_4326[\"geometry\"][0]\n",
        "\n",
        "# Restaurants inside the MultiPoly\n",
        "tags = {\"amenity\": \"restaurant\"}\n",
        "restaurants_gdf = ox.features_from_polygon(poly, tags)\n",
        "\n",
        "# Reprojection to EPSG:3857 fpr distance calculation\n",
        "filtered_gdf.to_crs(epsg=3857, inplace=True)\n",
        "restaurants_gdf.to_crs(epsg=3857, inplace=True)\n",
        "\n",
        "restaurants_gdf.explore()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(restaurants_gdf))"
      ],
      "metadata": {
        "id": "WmnL5Jgya9QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsC5EfNooWwK"
      },
      "outputs": [],
      "source": [
        "# Function for calculation of the shortest disatnce between an Airbnb offer to a restaurant\n",
        "def nearest_distance(point, other_gdf):\n",
        "    distances = other_gdf.geometry.distance(point)\n",
        "    return distances.min()\n",
        "\n",
        "# Distance calculation for restaurants\n",
        "filtered_gdf['dist_restaurant'] = filtered_gdf.geometry.apply(lambda x: nearest_distance(x, restaurants_gdf))\n",
        "\n",
        "# Correlation between dist_restaurant and price\n",
        "corr_restau, p_restau = spearmanr(filtered_gdf['dist_restaurant'], filtered_gdf['price'])\n",
        "print(f\"Spearman-Correlation: {corr_restau}, p-Value: {p_restau}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e85sDAe_oWwL"
      },
      "outputs": [],
      "source": [
        "# Railways\n",
        "tags = {\"railway\": \"station\",\n",
        "        \"railway\": \"subway_entrance\"}\n",
        "\n",
        "railway_gdf = ox.features_from_polygon(poly, tags)\n",
        "railway_gdf.to_crs(epsg=3857, inplace=True)\n",
        "filtered_gdf.explore()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(railway_gdf))"
      ],
      "metadata": {
        "id": "mW3lzpEebnD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FxIWER_oWwL"
      },
      "outputs": [],
      "source": [
        "filtered_gdf['dist_railway'] = filtered_gdf.geometry.apply(lambda x: nearest_distance(x, railway_gdf))\n",
        "\n",
        "corr_railway, p_railway = spearmanr(filtered_gdf['dist_railway'], filtered_gdf['price'])\n",
        "print(f\"Spearman-Correlation: {corr_railway}, p-Value: {p_railway}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7tnfJIRoWwM"
      },
      "outputs": [],
      "source": [
        "# Attractions\n",
        "tags = {\"tourism\": \"attraction\",}\n",
        "attraction_gdf = ox.features_from_polygon(poly, tags)\n",
        "attraction_gdf.to_crs(epsg=3857, inplace=True)\n",
        "attraction_gdf.explore()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(attraction_gdf))"
      ],
      "metadata": {
        "id": "HkZp_A_Lbxm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MXFCt3R2z1j"
      },
      "outputs": [],
      "source": [
        "filtered_gdf['dist_attraction'] = filtered_gdf.geometry.apply(lambda x: nearest_distance(x, attraction_gdf))\n",
        "\n",
        "corr_attraction, p_attraction = spearmanr(filtered_gdf['dist_attraction'], filtered_gdf['price'])\n",
        "print(f\"Spearman-Correlation: {corr_attraction}, p-Value: {p_attraction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyZcgDkOzcTA"
      },
      "outputs": [],
      "source": [
        "# Coastline\n",
        "tags = {\"natural\": \"coastline\"}\n",
        "\n",
        "# Bounding Box (minx, miny, maxx, maxy)\n",
        "bounds = multi_poly_4326.total_bounds\n",
        "\n",
        "# Shapely polygon\n",
        "poly = box(*bounds)\n",
        "\n",
        "coastline_gdf = ox.features_from_polygon(poly, tags)\n",
        "\n",
        "coastline_gdf.to_crs(epsg=3857, inplace=True)\n",
        "coastline_gdf = coastline_gdf[(coastline_gdf.geometry.type == 'LineString') | (coastline_gdf.geometry.type == 'MultiLineString')]\n",
        "coastline_gdf.explore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVMLpZnzz3KJ"
      },
      "outputs": [],
      "source": [
        "# Distance to coastline\n",
        "coastline_geom = coastline_gdf.geometry.union_all()\n",
        "filtered_gdf[\"dist_coastline\"] = filtered_gdf.geometry.distance(coastline_geom)\n",
        "filtered_gdf[\"dist_coastline\"]\n",
        "\n",
        "# Correlation between dist_restaurant and price\n",
        "corr_coast, p_coast = spearmanr(filtered_gdf['dist_coastline'], filtered_gdf['price'])\n",
        "print(f\"Spearman-Correlation: {corr_coast}, p-Value: {p_coast}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpZ_2nIaoWwQ"
      },
      "outputs": [],
      "source": [
        "# Distance based  features\n",
        "dist_cols = ['dist_railway', 'dist_attraction', 'dist_restaurant', \"dist_coastline\"]\n",
        "\n",
        "# Calculation of correlations with price\n",
        "correlations = {}\n",
        "for col in dist_cols:\n",
        "    corr, _ = spearmanr(filtered_gdf[col], filtered_gdf['price'])\n",
        "    correlations[col] = corr\n",
        "\n",
        "corr_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['Spearman correlation'])\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Distance variables vs. price')\n",
        "plt.ylabel('Distance variable')\n",
        "plt.xlabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Vhqpni3V4z"
      },
      "source": [
        "Suitable features:\n",
        "- room_type\n",
        "- neighborhood_group,\n",
        "- neighborhood\n",
        "- dist_attraction\n",
        "- dist_coastline\n",
        "- dist_restaurant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufNWmYg53rbN"
      },
      "outputs": [],
      "source": [
        "# Selection of features\n",
        "features_df = filtered_gdf[['price_log','neighbourhood_group', 'room_type','neighbourhood','calculated_host_listings_count', 'minimum_nights', 'availability_365', 'dist_attraction', 'dist_coastline', 'dist_restaurant', 'reviews_per_month', 'number_of_reviews']]\n",
        "features_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot-encoding for cat vars\n",
        "features_encoded = pd.get_dummies(features_df, columns=['room_type', 'neighbourhood_group','neighbourhood'], drop_first=True)\n",
        "#features_encoded = features_df"
      ],
      "metadata": {
        "id": "oZB8F4SnGn8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYM5qaN-DViT"
      },
      "source": [
        "Model training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEArupxSFyzb"
      },
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "X = features_encoded.drop(\"price_log\", axis=1)\n",
        "y = features_encoded[\"price_log\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------------------- Optuna Tuning for XGBoost --------------------\n",
        "def objective_xgb(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 500),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
        "    }\n",
        "    model = XGBRegressor(**params, random_state=42, verbosity=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = root_mean_squared_error(y_test, preds)\n",
        "    return rmse\n",
        "\n",
        "study_xgb = optuna.create_study(direction=\"minimize\")\n",
        "study_xgb.optimize(objective_xgb, n_trials=25)\n",
        "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
        "print(\"Best XGBoost RMSE\", study_xgb.best_value)\n",
        "\n",
        "# -------------------- Optuna Tuning for CatBoost --------------------\n",
        "def objective_cat(trial):\n",
        "    params = {\n",
        "        \"iterations\": trial.suggest_int(\"iterations\", 5, 500),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 2, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
        "    }\n",
        "    model = CatBoostRegressor(**params, verbose=0, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = root_mean_squared_error(y_test, preds)\n",
        "    return rmse\n",
        "\n",
        "study_cat = optuna.create_study(direction=\"minimize\")\n",
        "study_cat.optimize(objective_cat, n_trials=25)\n",
        "print(\"Best CatBoost params:\", study_cat.best_params)\n",
        "print(\"CatBoost RMSE:\", study_cat.best_value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final XGBoost model\n",
        "xgboost_model = XGBRegressor(**study_xgb.best_params, random_state=42, verbosity=0)\n",
        "xgboost_model.fit(X_train, y_train)\n",
        "\n",
        "xgboost_preds_log = xgboost_model.predict(X_test)\n",
        "xgboost_rmse_log = root_mean_squared_error(y_test, xgboost_preds_log)\n",
        "\n",
        "xgboost_preds_dollar = np.exp(xgboost_preds_log)\n",
        "y_test_dollar = np.exp(y_test)\n",
        "xgboost_rmse_dollar = root_mean_squared_error(y_test_dollar, xgboost_preds_dollar)\n",
        "\n",
        "print(f\"XGBoost RMSE (log scale): {xgboost_rmse_log}\")\n",
        "print(f\"XGBoost RMSE (dollar): {xgboost_rmse_dollar}\")\n",
        "# Feature Importances (Gini importance / Gain)\n",
        "importances = xgboost_model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Ausgabe in Konsole\n",
        "print(\"\\nCatBoost Feature Importances:\")\n",
        "print(importance_df.to_string(index=False))\n",
        "\n",
        "CatBoost RMSE (log scale): 0.33777854302676613"
      ],
      "metadata": {
        "id": "lSZr_Zq5W34I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Catboost model\n",
        "catboost_model = CatBoostRegressor(**study_cat.best_params, verbose=0, random_state=42)\n",
        "catboost_model.fit(X_train, y_train)\n",
        "\n",
        "catboost_preds_log = catboost_model.predict(X_test)\n",
        "catboost_rmse_log = root_mean_squared_error(y_test, catboost_preds_log)\n",
        "\n",
        "catboost_preds_dollar = np.exp(catboost_preds_log)\n",
        "y_test_dollar = np.exp(y_test)\n",
        "catboost_rmse_dollar = root_mean_squared_error(y_test_dollar, catboost_preds_dollar)\n",
        "\n",
        "print(f\"CatBoost RMSE (log scale): {catboost_rmse_log}\")\n",
        "print(f\"CatBoost RMSE (dollar): {catboost_rmse_dollar}\")\n",
        "# Feature Importances\n",
        "importances = catboost_model.get_feature_importance()\n",
        "feature_names = X_train.columns\n",
        "\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Ausgabe in Konsole\n",
        "print(\"\\nCatBoost Feature Importances:\")\n",
        "print(importance_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "cm8pf4l4W7aJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}